{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "Path('covid.db').touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('covid.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with all three CSV's\n",
    "covid_data = { \"states\" : { \"file\" : \"Resources/us-states.csv\",\n",
    "                    \"schema\" : '''CREATE TABLE states (date text, state text, cases int, deaths int)'''},\n",
    "         \"prison\" : { \"file\" : \"Resources/covid_prison_cases.csv\",\n",
    "                    \"schema\" : '''CREATE TABLE prison (name text, total_staff_deaths int, total_prisoner_cases int, total_prisoner_deaths int, as_of_date text )'''},\n",
    "         \"deaths\" : {\"file\" :\"Resources/3_covid_tracking_project_historical_testing_numbers_and_covid_deaths_by_state.csv\",\n",
    "                               \"schema\" : '''CREATE TABLE deaths (stage text, date text, total_population int, cumulative_deaths int,deaths_increase int, last_update_et text)'''}\n",
    "       }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame for all three csv's\n",
    "\n",
    "for k in covid_data:\n",
    "    d = pd.read_csv(covid_data[k][\"file\"])\n",
    "    covid_data[k][\"df\"] = d\n",
    "    \n",
    "states_df = covid_data[\"states\"][\"df\"]\n",
    "prison_df = covid_data[\"prison\"][\"df\"]\n",
    "deaths_df = covid_data[\"deaths\"][\"df\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the columns that needed for the analysis\n",
    "states_df = states_df.loc[:, (\"date\",\"state\",\"cases\",\"deaths\")]\n",
    "prison_df = prison_df.loc[:, (\"name\",\"total_prisoner_cases\",\"total_prisoner_deaths\",\"as_of_date\")]\n",
    "deaths_df = deaths_df.loc[:, (\"state\",\"date\",\"cumulative_deaths\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "states_df.rename(columns = {\"date\" : \"Date\",\"state\":\"State\",\"cases\":\"Number of Cases\", \"deaths\":\"Number of Deaths\"}, inplace = True)\n",
    "prison_df.rename(columns = {\"as_of_date\":\"Date\", \"name\" : \"State\", \"total_prisoner_cases\":\"Total Prisoner Cases\",\"total_prisoner_deaths\":\"Total Prisoner Deaths\", }, inplace = True)\n",
    "deaths_df.rename(columns = {\"date\":\"Date\",\"state\" : \"State\",\"cumulative_deaths\":\"Cumulative Prisoner Deaths\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing the columns\n",
    "states_df = states_df[[\"Date\",\"State\", \"Number of Cases\", \"Number of Deaths\"]]\n",
    "prison_df = prison_df[[\"Date\", \"State\", \"Total Prisoner Cases\",\"Total Prisoner Deaths\"]]\n",
    "deaths_df = deaths_df[[\"Date\",\"State\",\"Cumulative Prisoner Deaths\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with missing data\n",
    "clean_states_df = states_df.dropna(how = 'any')\n",
    "clean_prison_df = prison_df.dropna(axis = 0, how = 'any')\n",
    "clean_deaths_df = deaths_df.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarapatel/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/sarapatel/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# change the date format\n",
    "\n",
    "clean_prison_df[('Date')] = pd.to_datetime(clean_prison_df[('Date')]).dt.strftime('%Y-%m-%d')\n",
    "clean_states_df[('Date')] = pd.to_datetime(clean_states_df[('Date')]).dt.strftime('%Y-%m-%d')\n",
    "clean_deaths_df[('Date')] = pd.to_datetime(clean_deaths_df[('Date')]).dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "clean_deaths_df = clean_deaths_df.set_index(['State', 'Date'])\n",
    "clean_states_df = clean_states_df.set_index(['State', 'Date'])\n",
    "clean_prison_df = clean_prison_df.set_index(['State', 'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if there are any rows with missing data\n",
    "# clean_death_df.count()\n",
    "# clean_states_df.count()\n",
    "# clean_prison_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort columns\n",
    "clean_deaths_df = clean_deaths_df.sort_values(['State', 'Date'], ascending=False)\n",
    "clean_states_df = clean_states_df.sort_values(['State', 'Date'], ascending=False)\n",
    "clean_prison_df = clean_prison_df.sort_values(['State', 'Date'], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hej not sure if we should merge them here or in the postgress?\n",
    "# same for teh calculations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_deaths_df.to_csv(\"Resources/cleaned_deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_states_df.to_csv(\"Resources/cleaned_deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prison_df.to_csv(\"Resources/cleaned_deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
