{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with all three CSV's\n",
    "covid_data = { \n",
    "         \"states\" : { \"file\" : \"Resources/original_states.csv\"},\n",
    "         \"prison\" : { \"file\" : \"Resources/original_prison.csv\"},\n",
    "         \"deaths\" : {\"file\" :\"Resources/original_deaths.csv\"}\n",
    "       }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame for all three csv's\n",
    "\n",
    "for k in covid_data:\n",
    "    d = pd.read_csv(covid_data[k][\"file\"])\n",
    "    covid_data[k][\"df\"] = d\n",
    "    \n",
    "states_df = covid_data[\"states\"][\"df\"]\n",
    "prison_df = covid_data[\"prison\"][\"df\"]\n",
    "deaths_df = covid_data[\"deaths\"][\"df\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the columns that needed for the analysis\n",
    "states_df = states_df.loc[:, (\"date\",\"state\",\"cases\",\"deaths\")]\n",
    "prison_df = prison_df.loc[:, (\"name\",\"total_prisoner_cases\",\"total_prisoner_deaths\",\"as_of_date\")]\n",
    "deaths_df = deaths_df.loc[:, (\"state\",\"date\",\"cumulative_deaths\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "states_df.rename(columns = {\"date\" : \"Date\",\"state\":\"State\",\"cases\":\"Number_of_Cases\", \"deaths\":\"Number_of_Deaths\"}, inplace = True)\n",
    "prison_df.rename(columns = {\"as_of_date\":\"Date\", \"name\" : \"State\", \"total_prisoner_cases\":\"Total_Prisoner_Cases\",\"total_prisoner_deaths\":\"Total_Prisoner_Deaths\", }, inplace = True)\n",
    "deaths_df.rename(columns = {\"date\":\"Date\",\"state\" : \"State\",\"cumulative_deaths\":\"Cumulative_Prisoner_Deaths\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing the columns\n",
    "states_df = states_df[[\"Date\",\"State\", \"Number_of_Cases\", \"Number_of_Deaths\"]]\n",
    "prison_df = prison_df[[\"Date\", \"State\", \"Total_Prisoner_Cases\",\"Total_Prisoner_Deaths\"]]\n",
    "deaths_df = deaths_df[[\"Date\",\"State\",\"Cumulative_Prisoner_Deaths\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with missing data\n",
    "clean_states_df = states_df.dropna(how = 'any')\n",
    "clean_prison_df = prison_df.dropna(axis = 0, how = 'any')\n",
    "clean_deaths_df = deaths_df.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21134 entries, 0 to 21133\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Date              21134 non-null  datetime64[ns]\n",
      " 1   State             21134 non-null  object        \n",
      " 2   Number_of_Cases   21134 non-null  int64         \n",
      " 3   Number_of_Deaths  21134 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 825.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarapatel/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/sarapatel/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# change the date format\n",
    "\n",
    "clean_prison_df['Date'] = pd.to_datetime(clean_prison_df['Date'])\n",
    "clean_states_df['Date'] = pd.to_datetime(clean_states_df['Date'])\n",
    "clean_deaths_df[('Date')] = pd.to_datetime(clean_deaths_df[('Date')])\n",
    "clean_states_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "clean_deaths_df = clean_deaths_df.set_index(['State', 'Date'])\n",
    "clean_states_df = clean_states_df.set_index(['State', 'Date'])\n",
    "clean_prison_df = clean_prison_df.set_index(['State', 'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if there are any rows with missing data\n",
    "# clean_death_df.count()\n",
    "# clean_states_df.count()\n",
    "# clean_prison_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Number_of_Cases  Number_of_Deaths\n",
      "State   Date                                         \n",
      "Wyoming 2021-03-21            55581               693\n",
      "        2021-03-20            55581               693\n",
      "        2021-03-19            55581               693\n",
      "        2021-03-18            55479               693\n",
      "        2021-03-17            55449               693\n",
      "...                             ...               ...\n",
      "Alabama 2020-03-17               39                 0\n",
      "        2020-03-16               29                 0\n",
      "        2020-03-15               23                 0\n",
      "        2020-03-14               12                 0\n",
      "        2020-03-13                6                 0\n",
      "\n",
      "[21134 rows x 2 columns]                     Cumulative_Prisoner_Deaths\n",
      "State   Date                                  \n",
      "Wyoming 2021-03-07                       682.0\n",
      "        2021-03-06                       682.0\n",
      "        2021-03-05                       682.0\n",
      "        2021-03-04                       682.0\n",
      "        2021-03-03                       682.0\n",
      "...                                        ...\n",
      "Alabama 2020-03-19                         0.0\n",
      "        2020-03-18                         0.0\n",
      "        2020-03-17                         0.0\n",
      "        2020-03-16                         0.0\n",
      "        2020-03-15                         0.0\n",
      "\n",
      "[18179 rows x 1 columns]                     Total_Prisoner_Cases  Total_Prisoner_Deaths\n",
      "State   Date                                                   \n",
      "Wyoming 2021-03-16                 846.0                    3.0\n",
      "        2021-03-09                 795.0                    3.0\n",
      "        2021-03-02                 789.0                    3.0\n",
      "        2021-02-23                 770.0                    3.0\n",
      "        2021-02-16                 742.0                    3.0\n",
      "...                                  ...                    ...\n",
      "Alabama 2020-04-21                   4.0                    1.0\n",
      "        2020-04-13                   0.0                    0.0\n",
      "        2020-04-06                   0.0                    0.0\n",
      "        2020-03-31                   0.0                    0.0\n",
      "        2020-03-26                   0.0                    0.0\n",
      "\n",
      "[2507 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# sort columns\n",
    "clean_deaths_df = clean_deaths_df.sort_values(['State', 'Date'], ascending=False)\n",
    "clean_states_df = clean_states_df.sort_values(['State', 'Date'], ascending=False)\n",
    "clean_prison_df = clean_prison_df.sort_values(['State', 'Date'], ascending=False)\n",
    "\n",
    "print(clean_states_df, clean_deaths_df, clean_prison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hej not sure if we should merge them here or in the postgress?\n",
    "# same for teh calculations?\n",
    "\n",
    "merged_df = pd.merge(clean_states_df, clean_deaths_df, how='left', left_on=[\"State\", \"Date\"], right_on=[\"State\", \"Date\"])\n",
    "merged_df = pd.merge(merged_df, clean_prison_df, how='left', left_on=[\"State\", \"Date\"], right_on=[\"State\", \"Date\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean File to a csv\n",
    "clean_deaths_df.to_csv(\"Resources/cleaned_deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean File to a csv\n",
    "clean_states_df.to_csv(\"Resources/cleaned_states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean File to a csv\n",
    "clean_prison_df.to_csv(\"Resources/cleaned_prison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merged to csv\n",
    "merged_df.to_csv(\"Resources/cleaned_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Connect to Postgres \"prison\" db\n",
    "engine = create_engine('postgresql://localhost:5432/prison')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Creation Error maybe already exists\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrames to Postgres DB \n",
    "# Added all data but only using merged table for analytics\n",
    "try: \n",
    "    clean_prison_df.to_sql('prison', engine)\n",
    "    clean_deaths_df.to_sql('deaths', engine)\n",
    "    clean_states_df.to_sql('states', engine)\n",
    "    merged_df.to_sql('merged', engine)\n",
    "except:\n",
    "    print(\"Table Creation Error maybe already exists\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key most likely addedd\n"
     ]
    }
   ],
   "source": [
    "# Add primary key to \"merged\" table that contains all cleaned data\n",
    "try:   \n",
    "    with engine.connect() as con:\n",
    "        con.execute('ALTER TABLE merged ADD PRIMARY KEY (\"State\", \"Date\");')    \n",
    "except:\n",
    "    print(\"Primary key most likely addedd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import MetaData\n",
    "\n",
    "# Using SQL Alchemy to Query DB \n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "metadata = MetaData()\n",
    "session = Session(engine)\n",
    "\n",
    "Merged = Base.classes.merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California 40908.0\n",
      "Texas 36539.0\n",
      "Florida 27129.0\n",
      "New York 35319.0\n",
      "Illinois 21273.0\n",
      "Ohio 11230.0\n",
      "Georgia 14242.0\n",
      "Pennsylvania 21687.0\n",
      "North Carolina 9342.0\n",
      "Arizona 13124.0\n",
      "Tennessee 9753.0\n",
      "New Jersey 21513.0\n",
      "Indiana 9989.0\n",
      "Michigan 15536.0\n",
      "Wisconsin 6436.0\n",
      "Massachusetts 14607.0\n",
      "Virginia 6474.0\n",
      "Missouri 6748.0\n",
      "Minnesota 6202.0\n",
      "Alabama 7688.0\n",
      "South Carolina 7283.0\n",
      "Louisiana 8912.0\n",
      "Colorado 5641.0\n",
      "Oklahoma 3564.0\n",
      "Kentucky 3780.0\n",
      "Maryland 7154.0\n",
      "Utah 1668.0\n",
      "Iowa 4906.0\n",
      "Washington 4285.0\n",
      "Arkansas 4895.0\n",
      "Kansas 3809.0\n",
      "Nevada 4278.0\n",
      "Mississippi 6056.0\n",
      "Connecticut 7119.0\n",
      "Nebraska 1920.0\n",
      "New Mexico 3295.0\n",
      "Idaho 1725.0\n",
      "Oregon 1957.0\n",
      "Puerto Rico None\n",
      "West Virginia 2028.0\n",
      "Rhode Island 2173.0\n",
      "South Dakota 1778.0\n",
      "North Dakota 1447.0\n",
      "Montana 1234.0\n",
      "Delaware 1101.0\n",
      "New Hampshire 1059.0\n",
      "Alaska 262.0\n",
      "Wyoming 596.0\n",
      "Maine 595.0\n",
      "District of Columbia 916.0\n",
      "Hawaii 410.0\n",
      "Vermont 175.0\n",
      "Guam None\n",
      "Virgin Islands None\n",
      "Northern Mariana Islands None\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "from sqlalchemy import desc, asc, func \n",
    "\n",
    "# Get Results by Date\n",
    "q = session.query(Merged).filter(Merged.Date == dt(2021, 2, 1))\n",
    "q.all()\n",
    "\n",
    "\n",
    "# Filter Max column\n",
    "qry = q.order_by(desc(Merged.Number_of_Cases))\n",
    "for row in qry:\n",
    "    print(row.State, row.Cumulative_Prisoner_Deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
